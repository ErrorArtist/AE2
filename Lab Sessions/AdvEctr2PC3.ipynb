{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2df443",
   "metadata": {},
   "source": [
    "## Advanced Econometrics 2 - Bootstrap Methods\n",
    "\n",
    "Computer Class 1c (Thursday)\n",
    "\n",
    "*Aim of this computer class*: compare inference based on first-order asymptotic theory to inference based on the bootstrap using a Monte Carlo (MC) simulation.\n",
    "\n",
    "The DGP for the data is the Gaussian first-order autoregressive\n",
    "$-$AR(1)$-$ model given by\n",
    "$$y_{t}=\\rho y_{t-1}+\\varepsilon _{t}, \\ \\ \\ \\ \\varepsilon _{t}\\sim N(0,1), \\ \\ \\ \\ \\ t=2,...,N$$\n",
    "with starting value\n",
    "$y_{1}\\sim N(0,1/(1-\\rho ^{2}))$. \n",
    "\n",
    "We estimating the model, an intercept and trend is included in the model $$y_{t}=\\rho y_{t-1}+\\mu +\\beta t+\\varepsilon _{t},$$ so $\\mu =0$ and $\\beta =0$ in the DGP. The parameter of interest is the AR(1) coefficient $\\rho$. \n",
    "\n",
    "Suppose we want to test $H_{0}:\\rho =\\rho _{0}$ against $H_{1}^{L}:\\rho <\\rho _{0}$, $H_{1}^{R}:\\rho >\\rho _{0}$ or\n",
    "$H_{1}^{2}:\\rho \\neq \\rho _{0}$. \n",
    "\n",
    "We are interested in estimating the size of inference procedures based on the standard normal distribution and\n",
    "critical values obtained by the bootstrap. Preferably, the bootstrap is higher-order correct, so the critical values should be based on \n",
    "$$T^{\\ast }=\\frac{\\hat{\\rho}^*-\\hat{\\rho}}{SE(\\hat{\\rho}^*)}.$$\n",
    "\n",
    "## Assignment\n",
    "\n",
    "### 1.  Study in some detail the simulation code shown in the cell below. Execute the program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495d8032",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OLS(y,X):\n",
    "    N,k = X.shape                   # number of observations and regressors\n",
    "    XXi = np.linalg.inv(X.T @ X)\n",
    "    b_ols = XXi @ (X.T @ y)\n",
    "    res = y-X @ b_ols\n",
    "    s2 = (res @ res)/(N-k)\n",
    "    SE = np.sqrt(s2*np.diag(XXi))\n",
    "    return b_ols,SE,res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e78b3c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=50\n",
      "\n",
      "True bias:  -0.143\n",
      "MC average of bootstrapped bias:  -0.108\n",
      "Rejection frequencies\n",
      "H1:rho< 0.90 based on Asymp:   0.378    Boot:   0.159\n",
      "H1:rho> 0.90 based on Asymp:   0.001    Boot:   0.043\n",
      "H1:rho<>0.90 based on Asymp:   0.247    Boot:   0.156\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "N=50                                     # number of observations\n",
    "print('N=%d\\n' %N)\n",
    "MCREP = 4000                             # number of Monte Carlo replications\n",
    "BOOTREP = 99                             # number of bootstrap replications\n",
    "const = np.ones(N-1)                     # vector with ones (constant)\n",
    "trend = np.arange(N-1)                   # trend\n",
    "rho_hat = np.zeros(MCREP)                # contains estimated rho\n",
    "tstat = np.zeros(MCREP)                  # contains t-stat for rho\n",
    "mean_rhoB = np.zeros(MCREP)              # mean of the bootstrapped estimator\n",
    "tB_low = np.zeros(MCREP)                 # lower critical value\n",
    "tB_high = np.zeros(MCREP)                # higher critical value\n",
    "tB_crit2 = np.zeros(MCREP)               # critical value based on absoluted t-stat\n",
    "coefB = np.zeros(BOOTREP)\n",
    "statB = np.zeros(BOOTREP)\n",
    "np.random.seed(314159)          # reproducibility\n",
    "rho=0.9                         # true parameter value\n",
    "ar1=np.array([1, -rho])         # AR parameters: y(t)=rho*y(t-1)+epsilon(t)\n",
    "ma0=np.array([1])               # MA parameters: we only have 1*epsilon(t)\n",
    "for i in range(MCREP):\n",
    "    y0 = np.random.normal(size=1)/np.sqrt(1-rho**2);           # draw start value ~ N(0,1/(1-rho^2))\n",
    "    eps = np.random.normal(size=N-1)\n",
    "    yt = signal.lfilter(ma0, ar1, np.concatenate((y0,eps)) )\n",
    "    y = yt[1:]\n",
    "    X = np.vstack((yt[:-1],const,trend)).T\n",
    "    b_ols,SE,res = OLS(y,X)\n",
    "    rho_hat[i] = b_ols[0]\n",
    "    ar1_hat=np.array([1, -b_ols[0]])\n",
    "    tstat[i]=(b_ols[0]-rho)/SE[0]\n",
    "    fit_deter=X[:,1:] @ b_ols[1:]\n",
    "    for b in range(BOOTREP):\n",
    "        index = np.random.randint(N-1,size=N-1)\n",
    "        epsB = np.copy(res[index])\n",
    "        yBt = signal.lfilter(ma0, ar1_hat, np.concatenate((y0,fit_deter+epsB)) )\n",
    "        yB = yBt[1:]\n",
    "        XB = np.vstack((yBt[:-1],const,trend)).T\n",
    "        bB_ols,SEB,resB = OLS(yB,XB)\n",
    "        coefB[b] = bB_ols[0]\n",
    "        statB[b]=(bB_ols[0]-rho_hat[i])/SEB[0]\n",
    "    mean_rhoB[i]=np.mean(coefB)\n",
    "    tB_low[i]=np.quantile(statB,0.05)\n",
    "    tB_high[i]=np.quantile(statB,0.95)\n",
    "    t2Bstat=abs(statB)\n",
    "    tB_crit2[i]=np.quantile(t2Bstat,0.95)\n",
    "print(\"True bias: %7.3f\" % (np.mean(rho_hat)-rho))\n",
    "bias_boot=mean_rhoB-rho_hat; print(\"MC average of bootstrapped bias: %7.3f\" % np.mean(bias_boot))\n",
    "print(\"Rejection frequencies\")\n",
    "rej1Lasym=(tstat<=-1.645);  rej1Lboot=(tstat<=tB_low)\n",
    "print(\"H1:rho< %4.2f based on Asymp: %7.3f    Boot: %7.3f\" % (rho,np.mean(rej1Lasym),np.mean(rej1Lboot)))\n",
    "rej1Rasym=(tstat>1.645);    rej1Rboot=(tstat>=tB_high)\n",
    "print(\"H1:rho> %4.2f based on Asymp: %7.3f    Boot: %7.3f\" % (rho,np.mean(rej1Rasym),np.mean(rej1Rboot)))\n",
    "rej2asym=(abs(tstat)>1.96); rej2boot=(abs(tstat)>tB_crit2)\n",
    "print(\"H1:rho<>%4.2f based on Asymp: %7.3f    Boot: %7.3f\" % (rho,np.mean(rej2asym),np.mean(rej2boot)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a5130",
   "metadata": {},
   "source": [
    "### 2.  How many bootstrap samples are generated within the whole MC simulation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d47d2fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "396000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4000*99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c84324d",
   "metadata": {},
   "source": [
    "### 3.  Look at the vectors `b_ols` and `bB_ols`. To what does `b_ols` refer to? Same question with respect to `bB_ols`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be12bb47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.76173981, -1.03626702,  0.03817633])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bB_ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f9cd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.81643125, -1.0103615 ,  0.02728157])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_ols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20689efd",
   "metadata": {},
   "source": [
    "### 4.  In the Python program, to what does the vector `t2Bstat` refer to?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ae572a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8d0c0df",
   "metadata": {},
   "source": [
    "### 5.  Look at the averages of the series: `rej1Lasym`, ` rej1Rasym`, `rej2asym`. What do these averages represent? Same question with respect to: `rej1Lboot`, `rej1Rboot`, ` rej2boot`. What is the Error in Rejection Probability (ERP) for the various testing procedures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dfe12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f33d1b7",
   "metadata": {},
   "source": [
    "### 6.  Verify the rejection frequencies as reported in the lecture for $N=50$ , $N=200$, $N=800$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d58b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad893534",
   "metadata": {},
   "source": [
    "### 7.  Consider the use of the restricted parameter values in the bootstrap DGP.\n",
    "\n",
    "Modify the Python code to get the following bootstrap DGP\n",
    "$$y_{t}^{\\ast }=\\rho _{0}y_{t-1}^{\\ast }+\\hat{\\mu}+\\hat{\\beta}t+\\varepsilon_{t}^{\\ast }$$\n",
    "and test statistic\n",
    "$$T^{\\ast }=\\frac{\\hat{\\rho}^{\\ast }-\\rho _{0}}{SE(\\hat{\\rho}^{\\ast })}.$$\n",
    "What is your conclusion? How could you obtain estimates of $\\mu$ and $\\beta$ under $H_{0}:\\rho =\\rho _{0}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96c0f85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
