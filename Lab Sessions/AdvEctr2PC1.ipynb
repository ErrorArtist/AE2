{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c4781e",
   "metadata": {},
   "source": [
    "## Advanced Econometrics 2 - Bootstrap Methods\n",
    "\n",
    "Computer Class 1a (Monday)\n",
    "\n",
    "*Aim of this computer class*: to gain practical experience of the\n",
    "Jackknife and Bootstrap in the simple case of i.i.d. data.\n",
    "\n",
    "Assume that $X_{i}$ is randomly sampled from the exponential distribution with parameter 1, i.e. \n",
    "$$P[X_{i}\\leq x]=\\left\\{ \\begin{array}{ll} 1-e^{-x}, & x\\geq 0 \\\\ \n",
    "0, & x<0.%\n",
    "\\end{array}%\n",
    "\\right.$$\n",
    "The density function equals $f(x)=e^{-x}$ for $x\\geq 0$ and 0 otherwise. For the exponential distribution with parameter $\\lambda$, we have $\\mathbb{E}[X_{i}]=\\lambda$ and $\\mathbb{V}[X_{i}]=\\lambda ^{2}$ (this definition can differ from what you have learned), so in this case we have $\\mathbb{E}[X_{i}]=1$ and $\\mathbb{V}[X_{i}]=1$.\n",
    "Suppose we are interest in estimating $\\mu$, $\\mu ^{2}$ and $\\mu ^{3}$ using the naive estimators $\\bar{X}$, $\\bar{X}^{2}$ and $\\bar{X}^{3}$. We know from theory, that $\\bar{X}$ is an unbiased estimator of $\\mu$,\n",
    "but this does not hold for $\\bar{X}^{2}$ (and $\\bar{X}^{3})$ with respect to $\\mu ^{2}$ (and $\\mu ^{3}$).\n",
    "\n",
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb60f65a",
   "metadata": {},
   "source": [
    "1.  Download the file ‘Excel\\_Jackknife.xlsx’ from Canvas and save it in\n",
    "    your AE2 subdirectory (create this directory first). Open the\n",
    "    file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b3dd72",
   "metadata": {},
   "source": [
    "2.  Column $B$ contains 10 observations $\\{x_{1},...,x_{10}\\}$. In rows\n",
    "    14-16, you see the estimates $\\bar{x}$, $\\bar{x}^{2}$ and\n",
    "    $\\bar{x}^{3}$. Calculate the $N$ jackknife values\n",
    "    $\\hat{\\theta}_{(-i)}$ for $i=1,...,10$. Row 14 should contain the\n",
    "    values for $\\hat{\\theta}=\\bar{X}$, while the two rows below should\n",
    "    contain the values for $\\hat{\\theta}=\\bar{X}^{2}$ and $%\n",
    "    \\hat{\\theta}=\\bar{X}^{3}$. You can use the selection indices in\n",
    "    columns $D$-$%\n",
    "    M$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c48789",
   "metadata": {},
   "source": [
    "3.  Determine the jackknife estimate of the bias of $\\hat{\\theta}$ in\n",
    "    column $Q$:\n",
    "    $$(N-1)(\\bar{\\theta}_{(-1)}-\\hat{\\theta}), \\ \\ \\ \\ \\ \\ \\ \\text{with}\\bar{%\n",
    "    \\theta}_{(-1)}=N^{-1}\\sum \\hat{\\theta}_{(-i)}$$ and the\n",
    "    bias-corrected jackknife estimate of $\\theta$ in column $S:$\n",
    "    $$\\hat{\\theta}_{Jack}^{BC}=N\\hat{\\theta}-(N-1)\\bar{\\theta}_{(-1)}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20a2ccc",
   "metadata": {},
   "source": [
    "4.  Determine the jackknife estimate of the standard error of estimator\n",
    "    $\\hat{\\theta}$ in column $V$:\n",
    "    $$SE_{Jack}[\\hat{\\theta}]=\\sqrt{\\frac{N-1}{N}\\sum (\\hat{\\theta}_{(-i)}-\\bar{%\n",
    "    \\theta}_{(-1)})^{2}}.$$ Using these standard errors, you can\n",
    "    calculate the $t$-statistics\n",
    "    $$T=\\frac{\\hat{\\theta}-\\theta _{0}}{SE_{Jack}[\\hat{\\theta}]}$$ for\n",
    "    testing $H_{0}^{1}:\\mu =1$, $H_{0}^{2}:\\mu ^{2}=1$ and\n",
    "    $H_{0}^{3}:\\mu\n",
    "    ^{3}=1$. Also calculate the test statistics using the bias-corrected\n",
    "    jackknife estimate $\\hat{\\theta}_{Jack}^{BC}$, i.e.\n",
    "    $$T^{BC}=\\frac{\\hat{\\theta}_{Jack}^{BC}-\\theta _{0}}{SE_{Jack}[\\hat{\\theta}]}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68558a5",
   "metadata": {},
   "source": [
    "5.  You can check your results using the next code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f651f9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(142857)\n",
    "x=np.array([0.01735423, 0.031117747, 0.338455167, 1.689662823, 3.392061009, 0.410903576, 0.478754693, 3.571679284, 0.63655284, 0.433513319])\n",
    "N=x.shape[0]\n",
    "jackknife_values=np.zeros((N,3))\n",
    "for j in range(N):\n",
    "    for i in range(3):\n",
    "        jackknife_values[j,i]=np.mean(np.delete(x,j))**(i+1)\n",
    "for i in range(3):\n",
    "    theta_hat      =np.mean(x)**(i+1)\n",
    "    theta_jack__ave=np.mean(jackknife_values[:,i])\n",
    "    bias_jack      =(N-1)*(theta_jack__ave-theta_hat)\n",
    "    theta_hat_BC   =N*theta_hat-(N-1)*theta_jack__ave\n",
    "    SE_jack        =np.sqrt((N-1)/N*np.sum((jackknife_values[:,i]-theta_jack__ave)**2))\n",
    "    t_uncor        =(theta_hat-1)/SE_jack\n",
    "    t_cor          =(theta_hat_BC-1)/SE_jack\n",
    "    print('Average^%d: Jackknife bias=%7.4f     Bias-cor=%7.4f     SE_Jack=%7.4f   t(uncor)=%7.4f   t(cor)=%7.4f' \n",
    "         % (i+1,bias_jack,theta_hat_BC,SE_jack,t_uncor,t_cor) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d0e44",
   "metadata": {},
   "source": [
    " 6.  Execute the code in the next cell. The vectors `ave1B`/`ave2B`/`ave3B` contain 100,000 bootstrap\n",
    "    replications of $\\bar{X}^{\\ast }$ / $\\bar{X}^{\\ast 2}$ / $\\bar{X}%\n",
    "    ^{\\ast 3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ca250",
   "metadata": {},
   "outputs": [],
   "source": [
    "REP=100000\n",
    "ave1B=np.zeros(REP)\n",
    "ave2B=np.zeros(REP)\n",
    "ave3B=np.zeros(REP)\n",
    "for b in range(REP):\n",
    "    index=np.random.randint(N,size=N)\n",
    "    xB=np.copy(x[index])\n",
    "    ave1B[b]=np.mean(xB)\n",
    "    ave2B[b]=np.mean(xB)**2\n",
    "    ave3B[b]=np.mean(xB)**3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222eb2b7",
   "metadata": {},
   "source": [
    "7.  Take a look at the histogram of the vector `ave1B`. This is the (simulated) bootstrap\n",
    "    distribution of $\\bar{X}%\n",
    "    ^{\\ast }$. The mean of $\\bar{X}^{\\ast }$, i.e.\n",
    "    $\\mathbb{E}[\\bar{X}^{\\ast }|%\n",
    "    \\hat{F}]$, is estimated by the sample average of the 100,000\n",
    "    bootstrap replications, i.e.\n",
    "    $$\\mathbb{E}[\\bar{X}^{\\ast }|\\hat{F}]\\approx \\frac{1}{B}\\sum_{b=1}^{B}\\bar{X}%\n",
    "    _{b}(=\\text{np.mean in Numpy}).$$ Determine the bootstrap\n",
    "    estimate of the bias of $\\hat{\\theta}:$\n",
    "    $$\\mathbb{E}[\\bar{X}^{\\ast }|\\hat{F}]-\\hat{\\theta},$$ and calculate\n",
    "    the (approximate) bias-corrected bootstrap estimate of $\\theta\n",
    "    :$\n",
    "    $$\\hat{\\theta}_{Boot}^{BC}=2\\hat{\\theta}-\\mathbb{E}[\\bar{X}^{\\ast }|\\hat{F}].$$\n",
    "    Repeat the calulation for the vectors `ave2B` and `ave3B`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b3926",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "px.histogram(x=ave1B,nbins=150,labels={'x':'ave1B'})  # make histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb1c072",
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1Hat=np.mean(x)    # estimate for mu based on original sample\n",
    "bias1=                  # estimated bias based on bootstrap histogram\n",
    "theta1HatBC=            # bias-corrected (BC) estimate\n",
    "# now for ave2B\n",
    "theta2Hat=\n",
    "bias2=\n",
    "theta2HatBC=\n",
    "# now for ave3B\n",
    "theta3Hat=\n",
    "bias3=\n",
    "thetaHatBC="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae1f3be",
   "metadata": {},
   "source": [
    "8.  The variance of $\\bar{X}^{\\ast }$, i.e.\n",
    "    $\\mathbb{V}[\\bar{X}^{\\ast }|%\n",
    "    \\hat{F}]$ is approximated by\n",
    "    $$\\mathbb{V}[\\bar{X}^{\\ast }|\\hat{F}]\\approx \\frac{1}{B-1}\\sum%\n",
    "    \\nolimits_{b=1}^{B}(\\bar{X}_{b}^{\\ast }-\\bar{X}_{mean}^{\\ast })^{2}(=\\text{np.var in Nump}).$$\n",
    "    Hence, $$SE_{Boot}[\\hat{\\theta}]=\\sqrt{\\mathbb{V}[\\bar{X}^{\\ast }|\\hat{F}]}(= \n",
    "    \\text{np.std in Numpy}).$$ Calculate the $t$-statistics\n",
    "    $$T=\\frac{\\hat{\\theta}-\\theta _{0}}{SE_{Boot}[\\hat{\\theta}]}$$ for\n",
    "    testing $H_{0}^{1}:\\mu =1$, $H_{0}^{2}:\\mu ^{2}=1$ and\n",
    "    $H_{0}^{3}:\\mu\n",
    "    ^{3}=1$. Also calculate the test statistics using the bias-corrected\n",
    "    bootstrap estimate $\\hat{\\theta}_{Boot}^{BC}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379048f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEtheta1Hat=            # standard error (SE_boot) based on bootstrap histogram\n",
    "T1  =                   # t-ratio based on theta1Hat and SE_boot\n",
    "T1BC=                   # t-ratio based on theta1HatBC and SE_boot\n",
    "# now for T2\n",
    "SEtheta2Hat=\n",
    "T2  =\n",
    "T2BC=\n",
    "# now for T3\n",
    "SEtheta3Hat=\n",
    "T3  =\n",
    "T3BC="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e67c416",
   "metadata": {},
   "source": [
    "9.  A Jupyter notebook to check your bootstrap results can be downloaded\n",
    "    from Canvas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
