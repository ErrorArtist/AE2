{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AE2 - Assignment on Panel Data (2025)\n",
    "\n",
    "| Nr|**Name**|**Student ID**|\n",
    "|---|--------|--------------|\n",
    "|1.|Olga Milovanova|12879436| \n",
    "|2.|Alessandro Bonetti|15855902| \n",
    "|3.|Bowen Ma|12960780|  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code\n",
    "This section contains the code needed to answer the 4 questions of the assignment's Analysis and produce the related results.\n",
    "\n",
    "The packages needed to run the code are:\n",
    "* NumPy\n",
    "* Pandas\n",
    "* Statsmodels\n",
    "* Matplotlib.pyplot\n",
    "* SciPy\n",
    "* Parallel, from joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PACKAGES NEEDED ---\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from joblib import Parallel, delayed # Parallel running to reduce running time of the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCTIONS ---\n",
    "\n",
    "## Function for vec operator\n",
    "def vec(mA):\n",
    "    return np.asmatrix(mA.ravel('F')).T # ravel flattens the inpute array into 1-dim\n",
    "                                      # F specifies flatten by columns\n",
    "                                      # asmatrix convert the input into a numpy matrix\n",
    "\n",
    "## Function for time-series or cross-sectional de-meaning\n",
    "def Demean(mA, iAxis):\n",
    "\n",
    "        if iAxis == 0:\n",
    "            # when iAxis=0 substract mean alnong column\n",
    "            mA = mA - np.mean(mA,axis=iAxis).reshape(1,int(np.shape(mA)[1-iAxis]))\n",
    "        else:\n",
    "            # when iAxis=0 substract mean alnong row\n",
    "            mA = mA - np.mean(mA,axis=iAxis).reshape(int(np.shape(mA)[1-iAxis]),1)\n",
    "\n",
    "        return mA\n",
    "\n",
    "## Function to generate the data\n",
    "def GenrData (iSizeT, iSizeN, dAlpha, iS):  # set iS =1 when calling Number of \"lagged\" periods to skip or warm up before considering valid data.\n",
    "    \n",
    "    mErrors  = np.random.randn(iSizeN, iSizeT+iS+1)\n",
    "    mDataY = np.zeros((iSizeN,iSizeT+iS+1))\n",
    "    for t in range(1,iSizeT+iS+1):\n",
    "        mDataY[:,[t]] = dAlpha*mDataY[:,[t-1]] +  mErrors[:,[t]]\n",
    "        \n",
    "    return (np.transpose(mDataY[:,iS+1:]), np.transpose(mDataY[:,iS:iSizeT+iS]))# dim (iSizeT, iSizeN)\n",
    "\n",
    "## Function for the FE estimator\n",
    "def FE(y,x):\n",
    "    '''\n",
    "    The function to calculate the fixed effect estimator\n",
    "    First we  demean the regressor and the dependent variable\n",
    "    Then we stack the variables to regress using OLS\n",
    "    '''\n",
    "    # First demean the variables\n",
    "    y_demeaned=vec(Demean(y, 0))\n",
    "    x_demeaned=vec(Demean(x, 0))\n",
    "\n",
    "    # Compute the FE estimator\n",
    "    alpha_hat = np.linalg.inv(x_demeaned.T @ x_demeaned) @ x_demeaned.T @ y_demeaned\n",
    "    # returns a (1,1) matrix\n",
    "\n",
    "    # Convert it to a scalar\n",
    "    alpha_hat = alpha_hat.item()\n",
    "\n",
    "    return alpha_hat\n",
    "\n",
    "## Function for the HPJ estimator\n",
    "def HPJ (mDataY, mDataX, dEstimator, Estimation): # input is dEstimator(FE_estimator) and  Estimation(FE function)\n",
    "\n",
    "    iSizeT,iSizeN = np.shape(mDataY)\n",
    "    iHalf = int(np.floor(iSizeT/2))\n",
    "\n",
    "    dEstimator1 = Estimation (mDataY[:iHalf,:], mDataX[:iHalf,:])\n",
    "    dEstimator2 = Estimation (mDataY[iHalf:,:], mDataX[iHalf:,:])\n",
    "    dHPJ = 2*dEstimator-0.5*(dEstimator1+dEstimator2)\n",
    "\n",
    "    return (dHPJ,dEstimator1,dEstimator2)\n",
    "\n",
    "## Function to generate the bootstrapped data\n",
    "def GenrDataBootstrap (iSizeT, iSizeN, dAlpha_bootstrap, vY0, mResiduals):\n",
    "\n",
    "    # Initialize matrix of observations\n",
    "    mDataY_B = np.zeros((iSizeN,iSizeT+1))\n",
    "\n",
    "    # Transpose mErrors_B and vY0 to guarantee data compatibility\n",
    "    mResiduals = np.transpose(mResiduals)\n",
    "    vY0 = np.transpose(vY0)\n",
    "\n",
    "    # Generate Rademacher weights\n",
    "    mWeights = np.random.choice([1, -1], size=(iSizeN, iSizeT))\n",
    "    # Generate bootstrapped residuals\n",
    "    mErrors_B = np.multiply(mResiduals, mWeights) # element-wise product\n",
    "\n",
    "    # Set initial condition on Y\n",
    "    mDataY_B[:,0] = vY0\n",
    "\n",
    "    for t in range(1, iSizeT+1):\n",
    "      # Generate Y\n",
    "      mDataY_B[:,[t]] = dAlpha_bootstrap * mDataY_B[:,[t-1]] + mErrors_B[:,[t-1]]\n",
    "\n",
    "    mDataY_lag_B = np.transpose(mDataY_B[:,:iSizeT])\n",
    "    mDataY_B = np.transpose(mDataY_B[:,1:])\n",
    "\n",
    "    return mDataY_B, mDataY_lag_B\n",
    "\n",
    "## Function for bootstrap\n",
    "def BootstrapMC (mResiduals, vY0, iB, dLevel, vNull, vEst, dAlpha_bootstrap, chosen_est):  # \n",
    "\n",
    "    iSizeT, iSizeN = np.shape(mResiduals)       # extract T and N\n",
    "    iSizeP = np.shape(vNull)[0]                 # number of different hypotheses to be tested\n",
    "    iSizeEst = len(vEst)                        # number of estimates to be tested\n",
    "\n",
    "    iUnitLow = int(np.floor((dLevel/2)*iB))     # define lower quantile unit\n",
    "    iUnitHigh = int(np.floor((1-dLevel/2)*iB))  # define upper quantile unit\n",
    "\n",
    "    mResB = np.zeros((iB,iSizeEst))             # array to store bootstrapped estimates\n",
    "    mResB[0,:] = vEst                           # include original estimate while constructing CI\n",
    "\n",
    "    # Compute bootstrapped estimates\n",
    "    for b in range(1,iB):\n",
    "\n",
    "        # Generate bootstrapped data\n",
    "        mDataY_B, mDataY_lag_B = GenrDataBootstrap (iSizeT, iSizeN, dAlpha_bootstrap, vY0, mResiduals)\n",
    "\n",
    "        dFE_B = FE (mDataY_B, mDataY_lag_B) # bootstrapped FE estimates\n",
    "        mResB[b,0] = dFE_B - dAlpha_bootstrap # center estimates around the value of alpha used in the bootstrap and store them\n",
    "\n",
    "        if chosen_est == 'HPJ':          \n",
    "          dFE_HPJ_B = HPJ (mDataY_B, mDataY_lag_B, dFE_B, FE)[0] # bootstrapped HPJ estimates\n",
    "          mResB[b,0] = dFE_HPJ_B - dAlpha_bootstrap # center estimates around the value of alpha used in the bootstrap and store them\n",
    "\n",
    "    # Sort bootstrapped estimates\n",
    "    mResB_Sorted = np.sort(mResB, axis=0)\n",
    "\n",
    "    # Initialize array to store rejections\n",
    "    mReject = np.zeros((iSizeEst, iSizeP)) # dimension is:\n",
    "                                # number of estimators to be tested\n",
    "                                # multiplied by number of hypotheses to be tested\n",
    "\n",
    "    # Run the test\n",
    "    for k in range(0, iSizeEst):\n",
    "        dLowQ = mResB_Sorted[iUnitLow, k]     # compute lower quantile\n",
    "        dHighQ = mResB_Sorted[iUnitHigh, k]   # compute upper quantile\n",
    "        dLow = dLowQ\n",
    "        dHigh = dHighQ\n",
    "\n",
    "        # Run and store test result\n",
    "        mReject[k,:] = np.where((vNull < dHigh) & (vNull > dLow), 0, 1)\n",
    "\n",
    "    return mReject.T\n",
    "\n",
    "## Function for the Monte Carlo study\n",
    "def MC_study (iSizeT, dKappa, dGamma, iM, iB):\n",
    "\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # To store estimation results\n",
    "    mResultsEstimation = np.asmatrix(np.zeros((iM,2)))\n",
    "    \n",
    "    # To store testing results for any choice of P. Standard P=1\n",
    "    iP = 1\n",
    "    mResultsTesting = np.zeros((iM,3*iP))\n",
    "\n",
    "    for m in range (0,iM):\n",
    "\n",
    "        # True value is a function of T,\\gamma,\\kappa\n",
    "        dAlpha_0 =  np.exp(-iSizeT**-dGamma)\n",
    "\n",
    "        iSizeN = int(iSizeT**(1/dKappa)) \n",
    "\n",
    "        mDataY, mDataY_lag = GenrData (iSizeT, iSizeN, dAlpha_0,iS) # generating the data\n",
    "\n",
    "        dFE = FE(mDataY, mDataY_lag)              # FE estimator\n",
    "        dFE_HPJ = HPJ(mDataY, mDataY_lag,dFE,FE) \n",
    "        dHPJ = dFE_HPJ[0]                         # HPJ estimator\n",
    "\n",
    "        mResultsEstimation[m,0] = dFE - dAlpha_0\n",
    "        mResultsEstimation[m,1] = dHPJ - dAlpha_0\n",
    "\n",
    "        # FE bootstrap initialization\n",
    "        vEst_FE = np.array([dFE])\n",
    "        dAlpha_bootstrap_FE = dFE\n",
    "        mResiduals_FE = mDataY - dFE * mDataY_lag\n",
    "        vNull_FE = np.array([dFE - dAlpha_0])              \n",
    "\n",
    "        # HPJ bootstrap initialization\n",
    "        vEst_HPJ = np.array([dHPJ])\n",
    "        dAlpha_bootstrap_HPJ = dHPJ\n",
    "        mResiduals_HPJ = mDataY - dHPJ * mDataY_lag\n",
    "        vNull_HPJ = np.array([dHPJ - dAlpha_0])\n",
    "\n",
    "        # Q4 bootstrap initialization\n",
    "        dAlpha_bootstrap = dAlpha_0\n",
    "        \n",
    "        vY0 = mDataY_lag[0,:]  # initial condition for bootstrap\n",
    "        dLevel = 0.05          # significance level\n",
    "\n",
    "        # Run bootstrap\n",
    "        mRejectFE = BootstrapMC (mResiduals_FE, vY0, iB, dLevel, vNull_FE, vEst_FE, dAlpha_bootstrap_FE, \"FE\")\n",
    "        mRejectHPJ = BootstrapMC (mResiduals_HPJ, vY0, iB, dLevel, vNull_HPJ, vEst_HPJ, dAlpha_bootstrap_HPJ, \"HPJ\")\n",
    "        mRejectQ4 = BootstrapMC (mResiduals_FE, vY0, iB, dLevel, vNull_FE, vEst_FE, dAlpha_bootstrap, \"FE\") # Only change dAlpha_bootstrap\n",
    "\n",
    "        # Store testing results\n",
    "        mResultsTesting[m,0] = mRejectFE[:,-1]  \n",
    "        mResultsTesting[m,1] = mRejectHPJ[:,-1]\n",
    "        mResultsTesting[m,2] = mRejectQ4[:,-1]\n",
    "        \n",
    "    # Bias for FE \n",
    "    vBias_FE = np.mean(mResultsEstimation[:, 0])\n",
    "\n",
    "    # Bias for HPJ \n",
    "    vBias_HPJ = np.mean(mResultsEstimation[:, 1])\n",
    "    \n",
    "    # RMSE\n",
    "    vRMSE = np.sqrt(np.mean(np.power(mResultsEstimation,2),axis=0))\n",
    "\n",
    "    # Rejection frequencies\n",
    "    mFreqFE = np.mean(mResultsTesting[:,0])\n",
    "    mFreqHPJ = np.mean(mResultsTesting[:,1])\n",
    "    mFreqQ4 = np.mean(mResultsTesting[:,2]) \n",
    "\n",
    "    print(\"Iteration complete for:\",\"T=\",iSizeT,\", N=\",iSizeN,\", alpha=\",np.round(dAlpha_0, 3)) \n",
    "\n",
    "    return vBias_FE,vBias_HPJ, vRMSE, mFreqFE, mFreqHPJ, mFreqQ4, dAlpha_0, iSizeN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed: 63.3min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed: 117.6min\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  27 | elapsed: 254.1min remaining: 203.3min\n",
      "[Parallel(n_jobs=-1)]: Done  18 out of  27 | elapsed: 297.7min remaining: 148.8min\n",
      "[Parallel(n_jobs=-1)]: Done  21 out of  27 | elapsed: 534.3min remaining: 152.7min\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed: 641.9min remaining: 80.2min\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 1575.3min finished\n"
     ]
    }
   ],
   "source": [
    "# --- OBTAINING RESULTS ---\n",
    "\n",
    "# Wrapper to handle a single simulation\n",
    "def run_simulation(T, kappa, gamma, iM, iB, iS):\n",
    "    \"\"\"\n",
    "    Run a single Monte Carlo study and return results for the given parameters.\n",
    "    \"\"\"\n",
    "    vBias_FE, vBias_HPJ, vRMSE, mFreqFE, mFreqHPJ, mFreq, dAlpha_0, iSizeN = MC_study(\n",
    "        T, kappa, gamma, iM, iB\n",
    "    )\n",
    "    return {\n",
    "        \"T\": T,\n",
    "        \"N\": iSizeN,\n",
    "        \"κ\": kappa,\n",
    "        \"γ\": gamma,\n",
    "        \"α\": dAlpha_0,\n",
    "        \"RMSE for FE estimator\": vRMSE[0, 0],  # RMSE for FE\n",
    "        \"RMSE for HPJ estimator\": vRMSE[0, 1],  # RMSE for HPJ\n",
    "        \"MC Bias for FE estimator\": vBias_FE,\n",
    "        \"MC Bias for HPJ estimator\": vBias_HPJ,\n",
    "        \"Rejection freq. FE\": mFreqFE,\n",
    "        \"Rejection freq. HPJ\": mFreqHPJ,\n",
    "        \"Rejection freq. Q4\": mFreq,\n",
    "    }\n",
    "\n",
    "# Parameters\n",
    "T_values = [20, 50, 100]\n",
    "kappa_values = [0.6, 0.8, 1.0]\n",
    "gamma_values = [0.75, 1.0, 1.25]\n",
    "iM = 4000\n",
    "iB = 199\n",
    "iS = 1\n",
    "\n",
    "# Run simulations in parallel\n",
    "results = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_simulation)(T, kappa, gamma, iM, iB, iS)\n",
    "    for T in T_values\n",
    "    for kappa in kappa_values\n",
    "    for gamma in gamma_values\n",
    ")\n",
    "\n",
    "# Create DataFrame directly from list of dictionaries\n",
    "df = pd.DataFrame(results)\n",
    "df = df.round(4).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>T</th>\n",
       "      <th>N</th>\n",
       "      <th>κ</th>\n",
       "      <th>γ</th>\n",
       "      <th>α</th>\n",
       "      <th>RMSE for FE estimator</th>\n",
       "      <th>RMSE for HPJ estimator</th>\n",
       "      <th>MC Bias for FE estimator</th>\n",
       "      <th>MC Bias for HPJ estimator</th>\n",
       "      <th>Rejection freq. FE</th>\n",
       "      <th>Rejection freq. HPJ</th>\n",
       "      <th>Rejection freq. Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.1373</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>-0.1365</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.1488</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>-0.1482</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.0442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>147</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>-0.1493</td>\n",
       "      <td>-0.0213</td>\n",
       "      <td>0.4812</td>\n",
       "      <td>0.0480</td>\n",
       "      <td>0.0532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>-0.1377</td>\n",
       "      <td>-0.0118</td>\n",
       "      <td>0.1342</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.0458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.1518</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>-0.1497</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>0.1730</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.0468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>42</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>-0.1509</td>\n",
       "      <td>-0.0221</td>\n",
       "      <td>0.1417</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>-0.1411</td>\n",
       "      <td>-0.0135</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>0.1576</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>-0.1529</td>\n",
       "      <td>-0.0234</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.0445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.1583</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>-0.1540</td>\n",
       "      <td>-0.0222</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0588</td>\n",
       "      <td>0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50</td>\n",
       "      <td>678</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>-0.0556</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.7352</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>50</td>\n",
       "      <td>678</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>-0.0618</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>0.0808</td>\n",
       "      <td>0.0635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>50</td>\n",
       "      <td>678</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>-0.0613</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>0.8588</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.0790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>-0.0559</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>-0.0620</td>\n",
       "      <td>-0.0063</td>\n",
       "      <td>0.3268</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.0520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>50</td>\n",
       "      <td>132</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>-0.0615</td>\n",
       "      <td>-0.0051</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>-0.0563</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0845</td>\n",
       "      <td>0.0392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0170</td>\n",
       "      <td>-0.0623</td>\n",
       "      <td>-0.0062</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>-0.0050</td>\n",
       "      <td>0.0905</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>-0.0275</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>0.0472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>-0.0313</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0782</td>\n",
       "      <td>0.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>2154</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>316</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>-0.0276</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>316</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>-0.0314</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>0.6040</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>0.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>316</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>-0.0309</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>-0.0279</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.9900</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>-0.0317</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>0.0650</td>\n",
       "      <td>0.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>-0.0312</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>0.1220</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      T     N    κ     γ       α  RMSE for FE estimator  \\\n",
       "0    20   147  0.6  0.75  0.8997                 0.1373   \n",
       "1    20   147  0.6  1.00  0.9512                 0.1488   \n",
       "2    20   147  0.6  1.25  0.9766                 0.1498   \n",
       "3    20    42  0.8  0.75  0.8997                 0.1402   \n",
       "4    20    42  0.8  1.00  0.9512                 0.1518   \n",
       "5    20    42  0.8  1.25  0.9766                 0.1528   \n",
       "6    20    20  1.0  0.75  0.8997                 0.1465   \n",
       "7    20    20  1.0  1.00  0.9512                 0.1576   \n",
       "8    20    20  1.0  1.25  0.9766                 0.1583   \n",
       "9    50   678  0.6  0.75  0.9482                 0.0557   \n",
       "10   50   678  0.6  1.00  0.9802                 0.0618   \n",
       "11   50   678  0.6  1.25  0.9925                 0.0614   \n",
       "12   50   132  0.8  0.75  0.9482                 0.0563   \n",
       "13   50   132  0.8  1.00  0.9802                 0.0623   \n",
       "14   50   132  0.8  1.25  0.9925                 0.0618   \n",
       "15   50    50  1.0  0.75  0.9482                 0.0573   \n",
       "16   50    50  1.0  1.00  0.9802                 0.0631   \n",
       "17   50    50  1.0  1.25  0.9925                 0.0626   \n",
       "18  100  2154  0.6  0.75  0.9689                 0.0276   \n",
       "19  100  2154  0.6  1.00  0.9900                 0.0313   \n",
       "20  100  2154  0.6  1.25  0.9968                 0.0309   \n",
       "21  100   316  0.8  0.75  0.9689                 0.0277   \n",
       "22  100   316  0.8  1.00  0.9900                 0.0315   \n",
       "23  100   316  0.8  1.25  0.9968                 0.0310   \n",
       "24  100   100  1.0  0.75  0.9689                 0.0282   \n",
       "25  100   100  1.0  1.00  0.9900                 0.0319   \n",
       "26  100   100  1.0  1.25  0.9968                 0.0314   \n",
       "\n",
       "    RMSE for HPJ estimator  MC Bias for FE estimator  \\\n",
       "0                   0.0256                   -0.1365   \n",
       "1                   0.0313                   -0.1482   \n",
       "2                   0.0300                   -0.1493   \n",
       "3                   0.0440                   -0.1377   \n",
       "4                   0.0473                   -0.1497   \n",
       "5                   0.0457                   -0.1509   \n",
       "6                   0.0640                   -0.1411   \n",
       "7                   0.0657                   -0.1529   \n",
       "8                   0.0634                   -0.1540   \n",
       "9                   0.0046                   -0.0556   \n",
       "10                  0.0077                   -0.0618   \n",
       "11                  0.0066                   -0.0613   \n",
       "12                  0.0103                   -0.0559   \n",
       "13                  0.0117                   -0.0620   \n",
       "14                  0.0106                   -0.0615   \n",
       "15                  0.0166                   -0.0563   \n",
       "16                  0.0170                   -0.0623   \n",
       "17                  0.0158                   -0.0619   \n",
       "18                  0.0017                   -0.0275   \n",
       "19                  0.0030                   -0.0313   \n",
       "20                  0.0022                   -0.0309   \n",
       "21                  0.0036                   -0.0276   \n",
       "22                  0.0042                   -0.0314   \n",
       "23                  0.0036                   -0.0309   \n",
       "24                  0.0062                   -0.0279   \n",
       "25                  0.0064                   -0.0317   \n",
       "26                  0.0058                   -0.0312   \n",
       "\n",
       "    MC Bias for HPJ estimator  Rejection freq. FE  Rejection freq. HPJ  \\\n",
       "0                     -0.0118              0.4142               0.1003   \n",
       "1                     -0.0221              0.5508               0.0882   \n",
       "2                     -0.0213              0.4812               0.0480   \n",
       "3                     -0.0118              0.1342               0.0945   \n",
       "4                     -0.0226              0.1730               0.0758   \n",
       "5                     -0.0221              0.1417               0.0542   \n",
       "6                     -0.0135              0.0905               0.1030   \n",
       "7                     -0.0234              0.1030               0.0832   \n",
       "8                     -0.0222              0.0853               0.0588   \n",
       "9                     -0.0004              0.7352               0.0980   \n",
       "10                    -0.0063              0.9552               0.0808   \n",
       "11                    -0.0052              0.8588               0.0230   \n",
       "12                    -0.0004              0.1872               0.0835   \n",
       "13                    -0.0063              0.3268               0.0740   \n",
       "14                    -0.0051              0.2198               0.0268   \n",
       "15                    -0.0004              0.0830               0.0845   \n",
       "16                    -0.0062              0.1212               0.0645   \n",
       "17                    -0.0050              0.0905               0.0362   \n",
       "18                     0.0011              0.9540               0.0872   \n",
       "19                    -0.0027              1.0000               0.0782   \n",
       "20                    -0.0019              0.9975               0.0165   \n",
       "21                     0.0011              0.2525               0.0798   \n",
       "22                    -0.0027              0.6040               0.0693   \n",
       "23                    -0.0019              0.3733               0.0140   \n",
       "24                     0.0009              0.1003               0.0853   \n",
       "25                    -0.0029              0.2130               0.0650   \n",
       "26                    -0.0021              0.1220               0.0240   \n",
       "\n",
       "    Rejection freq. Q4  \n",
       "0               0.0465  \n",
       "1               0.0442  \n",
       "2               0.0532  \n",
       "3               0.0458  \n",
       "4               0.0468  \n",
       "5               0.0420  \n",
       "6               0.0432  \n",
       "7               0.0445  \n",
       "8               0.0430  \n",
       "9               0.0428  \n",
       "10              0.0635  \n",
       "11              0.0790  \n",
       "12              0.0488  \n",
       "13              0.0520  \n",
       "14              0.0548  \n",
       "15              0.0392  \n",
       "16              0.0395  \n",
       "17              0.0430  \n",
       "18              0.0472  \n",
       "19              0.0525  \n",
       "20              0.0738  \n",
       "21              0.0450  \n",
       "22              0.0488  \n",
       "23              0.0528  \n",
       "24              0.0485  \n",
       "25              0.0465  \n",
       "26              0.0472  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Results \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias (Question 1)\n",
    "\n",
    "### Fixed effects estimator (FE)\n",
    "\n",
    "- In virtually every scenario the bias for the FE estimator is negative, which aligns with established literature. \n",
    "\n",
    "- For $T$ smaller (i.e., $T=20$), the bias is larger with respect to the other scenarios. \n",
    "\n",
    "    We can think of this situation as a setting with T fixed. The reason for the larger bias is the so called \"Nickell bias\" (Nickell, 1981): for T fixed, the asymptotic result is that the FE estimator is inconsistent. \n",
    "    \n",
    "    This distortion arises because the first difference transformation (used to get rid of the fixed effects) introduces into the panel data model a correlation between the (transformed) lagged dependent variable and the (transformed) error term. This is known as the *incidental parameters problem*.\n",
    "\n",
    "- The bias diminishes as $T$ increases to $50$, and it becomes even smaller for $T=100$, which reflects improved consistency. \n",
    "\n",
    "    This confirms the asymptotic result for a setting with $T$ large (and $N$ large), where the FE estimator becomes consistent. Analytically, we can write: $E(\\hat{a}_{FE}) - \\alpha_0 \\xrightarrow{p} -\\frac{1}{T} (1+\\alpha_0)$, which goes to $0$ as $T$ increases.\n",
    "    \n",
    "    Howevever, for T large, the FE estimator still displays an asymptotic bias which can make standard inference unreliable (Hahn and Kuersteiner, 2002). This becomes evident if we consider the expression:\n",
    "\n",
    "    $\\sqrt{N T} (\\hat{a}_{FE} - \\alpha_0) \\xrightarrow{d} \\mathcal{N}(-k(1+\\alpha_0), (1-\\alpha_0^2))$\n",
    "\n",
    "    where $N, T \\to \\infty, \\quad N/T \\to k^2 \\in [0, \\infty)$.\n",
    "\n",
    "    The asymptotic bias $-k(1+\\alpha_0)$ is negligible only if $N/T \\approx 0$, i.e., when the ratio between $N$ and $T$ is very small in the sample at hand. This is clearly not the case for some of our parameter combinations. \n",
    "    \n",
    "    For example, let us consider the scenario(s) where $T=100$. Here, the FE estimate is reliable across the different values of $N$, as the bias hovers around $3\\%$ of the true value of $\\alpha$. However, if our concern is not only estimation, but also inference, we must pay attention to the ratio $N/T$. For larger values of $N$ (and keeping $T=100$), $k$ in the previous expression becomes larger, making the asymptotic bias bigger and inference results less reliable.\n",
    "\n",
    "    We can obtain the approximate value of the asymptotic bias $-k(1+\\alpha_0)$ by multiplying by $\\sqrt{N T}$ the FE bias (contained in the column *MC Bias for FE estimator* of the table at the end of the report).\n",
    "\n",
    "### Half Panel Jackknife estimator (HPJ)\n",
    "\n",
    "- The bias for the HPJ estimator is significantly smaller compared to the FE estimator. \n",
    "- Indeed, the HPJ estimator is designed to deal with the Nickell Bias by explicitly estimating and subtracting the bias through a Jackknife-based method. \n",
    "- The bias of the HPJ estimator almost always takes negative values (although very small). As the bias for the FE estimator is usually negative, this could possibly signal that in our data the HPJ procedure falls slightly short of consistently offsetting the FE bias.\n",
    "\n",
    "## RMSE (Question 1)\n",
    "\n",
    "### FE estimator\n",
    "\n",
    "- RMSE values for the FE estimator generally decline as $T$ increases.\n",
    "\n",
    "- They are highest when $T$ is small and $\\gamma$ is large. Indeed, a larger value of $\\gamma$ is associated to a true value of $\\alpha$ closer to 1 (unit root), which in turn implies a more persistent AR(1) process and noisier estimates.\n",
    "\n",
    "### HPJ estimator\n",
    "\n",
    "- RMSE is considerably lower than FE’s under all parameter scenarios, particularly as $T$ grows. \n",
    "\n",
    "- This shows the effectiveness of Jackknife-based bias correction in dealing with the Nickell bias. \n",
    "\n",
    "- We also observe that results are robust to values of $\\alpha \\approx 1$ (very close to unit root). This shows the practical superiority of the Jackknife bias correction with respect to analytical approaches like the one illustrated by Hahn and Kuersteiner (2002, p.1645), where \"the bias correction for the stationary case is not expected to work under the unit root\".\n",
    "\n",
    "## Rejection Frequencies\n",
    "\n",
    "### FE rejection frequencies (Question 2)\n",
    "- FE rejection frequencies can be extremely high when the ratio $N/T$ is high. This indicates that the confidence intervals are undercovering the true parameter value (over-rejection of the null).\n",
    "    \n",
    "    For example, rejection frequencies approach 1 when $N=2154$ and $T=100$, so that $N/T=21.54$.\n",
    "    \n",
    "    Instead, if we consider $N=100$ and $T=100$ (i.e. $N/T=1$), rejection frequencies become much lower: between $10\\%$ and $20\\%$.\n",
    "\n",
    "    Let us consider parameter combinations with the same ratio $N/T=1$. Rejection frequencies for $(N=50, T=50)$, and for $(N=20, T=20)$ are slightly lower than for $(N=100, T=100)$, but they are of a comparable order of magnitude, as they hover around $10\\%$. \n",
    "    \n",
    "- This shows that what matters for inference based on the FE estimator is the ratio between $N$ and $T$, not simply the value of $T$.\n",
    "\n",
    "- This result confirms our previous point about the unreliability of inference based on the FE estimator when $N/T$ is sizeable. Indeed, if $N/T$ is not small enough, the asymptotic bias $-k(1+\\alpha_0)$ is not negligible, which badly distorts inference procedures.\n",
    "\n",
    "- We also notice that, *ceteris paribus*, values of $\\gamma=1$ inflate rejection frequencies.\n",
    "\n",
    "- According to Gonçalves and Kaffo (2015), the RW bootstrap applied to the (biased) FE estimator should be able to give acceptable results in terms of inference, thanks to the \"asymptotic validity of a bootstrap percentile-t interval based on $t_{\\hat{\\theta}^{*}_{rd}}$ [the bootstrapped t-statistic]\" (ibid.). They argue that \"the recursive-design bootstrap contains a built-in bias correction term that mimics the incidental parameter bias induced by the individual fixed effects\" (p.411). However, this asymptotic property seems not to be valid in our finite-sample environment. Our results indicate that the built-in bias correction term of RWB may not be enough to deal with the FE bias and provide reasonable rejection frequencies.\n",
    "\n",
    "### HPJ rejection frequencies (Question 3)\n",
    "- The HPJ rejection rates are generally closer to the nominal $5\\%$, but they still can be higher for smaller $T$.\n",
    "\n",
    "- For larger $T$, they tend closer to the nominal significance rate, and show significantly better results than the FE rejection rates.\n",
    "\n",
    "- For larger $\\gamma$ (=larger $\\alpha_0$) the rejection rates decrease significantly.\n",
    "\n",
    "- Differently from the FE estimator, the ratio $N/T$ does not have influence rejection frequencies. This is due to the fact that the HPJ estimator explicitly corrects for the asymptotic bias $-k(1+\\alpha_0)$, neutralizing the effect of a large $N/T$ ratio.\n",
    "\n",
    "- In general, these results seem to support one of the main conclusions of Gonçalves and Kaffo (2015, p.413), i.e., the validity of a recursive-design bootstrap applied to a bias-corrected fixed effect estimator (the HPJ estimator in our case). \n",
    "\n",
    "- However, the inference refinement brought about by the bias-corrected estimator (with respect to the *biased* FE estimator) is much higher than implied by Gonçalves and Kaffo (2015).\n",
    "\n",
    "### Question 4 Rejection Frequencies\n",
    "- Setting the bootstrap DGP to the true $\\alpha_0$ (rather than $\\hat{\\alpha}_{FE}$) brings the rejection rates mostly closer to the nominal $5\\%$.\n",
    "\n",
    "- Even for large $T$, these rejection rates stay around $0.04-0.08$, indicating much more stable coverage than relying on the biased FE estimate.\n",
    "\n",
    "- This result underlines once more the distortion introduced into inference by the asymptotic bias of the FE estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy of final results:\n",
    "\n",
    "| | **T**  | **N**   | **κ**  | **γ**   | **α**_0| **RMSE for FE estimator** | **RMSE for HPJ estimator** | **MC Bias for FE estimator** | **MC Bias for HPJ estimator** | **Rejection freq. FE** | **Rejection freq. HPJ** | **Rejection freq. Q4** |\n",
    "|-------:|-------:|--------:|------:|-------:|---------:|--------------------------:|---------------------------:|----------------------------:|-----------------------------:|-----------------------:|------------------------:|------------------------:|\n",
    "| 0      | 20     | 147     | 0.6   | 0.75    | 0.8997    | 0.1373                    | 0.0256                     | -0.1365                     | -0.0118                      | 0.4142                 | 0.1003                  | 0.0465                  |\n",
    "| 1      | 20     | 147     | 0.6   | 1.00    | 0.9512    | 0.1488                    | 0.0313                     | -0.1482                     | -0.0221                      | 0.5508                 | 0.0882                  | 0.0442                  |\n",
    "| 2      | 20     | 147     | 0.6   | 1.25    | 0.9766    | 0.1498                    | 0.0300                     | -0.1493                     | -0.0213                      | 0.4812                 | 0.0480                  | 0.0532                  |\n",
    "| 3      | 20     | 42      | 0.8   | 0.75    | 0.8997    | 0.1402                    | 0.0440                     | -0.1377                     | -0.0118                      | 0.1342                 | 0.0945                  | 0.0458                  |\n",
    "| 4      | 20     | 42      | 0.8   | 1.00    | 0.9512    | 0.1518                    | 0.0473                     | -0.1497                     | -0.0226                      | 0.1730                 | 0.0758                  | 0.0468                  |\n",
    "| 5      | 20     | 42      | 0.8   | 1.25    | 0.9766    | 0.1528                    | 0.0457                     | -0.1509                     | -0.0221                      | 0.1417                 | 0.0542                  | 0.0420                  |\n",
    "| 6      | 20     | 20      | 1.0   | 0.75    | 0.8997    | 0.1465                    | 0.0640                     | -0.1411                     | -0.0135                      | 0.0905                 | 0.1030                  | 0.0432                  |\n",
    "| 7      | 20     | 20      | 1.0   | 1.00    | 0.9512    | 0.1576                    | 0.0657                     | -0.1529                     | -0.0234                      | 0.1030                 | 0.0832                  | 0.0445                  |\n",
    "| 8      | 20     | 20      | 1.0   | 1.25    | 0.9766    | 0.1583                    | 0.0634                     | -0.1540                     | -0.0222                      | 0.0853                 | 0.0588                  | 0.0430                  |\n",
    "| 9      | 50     | 678     | 0.6   | 0.75    | 0.9482    | 0.0557                    | 0.0046                     | -0.0556                     | -0.0004                      | 0.7352                 | 0.0980                  | 0.0428                  |\n",
    "| 10     | 50     | 678     | 0.6   | 1.00    | 0.9802    | 0.0618                    | 0.0077                     | -0.0618                     | -0.0063                      | 0.9552                 | 0.0808                  | 0.0635                  |\n",
    "| 11     | 50     | 678     | 0.6   | 1.25    | 0.9925    | 0.0614                    | 0.0066                     | -0.0613                     | -0.0052                      | 0.8588                 | 0.0230                  | 0.0790                  |\n",
    "| 12     | 50     | 132     | 0.8   | 0.75    | 0.9482    | 0.0563                    | 0.0103                     | -0.0559                     | -0.0004                      | 0.1872                 | 0.0835                  | 0.0488                  |\n",
    "| 13     | 50     | 132     | 0.8   | 1.00    | 0.9802    | 0.0623                    | 0.0117                     | -0.0620                     | -0.0063                      | 0.3268                 | 0.0740                  | 0.0520                  |\n",
    "| 14     | 50     | 132     | 0.8   | 1.25    | 0.9925    | 0.0618                    | 0.0106                     | -0.0615                     | -0.0051                      | 0.2198                 | 0.0268                  | 0.0548                  |\n",
    "| 15     | 50     | 50      | 1.0   | 0.75    | 0.9482    | 0.0573                    | 0.0166                     | -0.0563                     | -0.0004                      | 0.0830                 | 0.0845                  | 0.0392                  |\n",
    "| 16     | 50     | 50      | 1.0   | 1.00    | 0.9802    | 0.0631                    | 0.0170                     | -0.0623                     | -0.0062                      | 0.1212                 | 0.0645                  | 0.0395                  |\n",
    "| 17     | 50     | 50      | 1.0   | 1.25    | 0.9925    | 0.0626                    | 0.0158                     | -0.0619                     | -0.0050                      | 0.0905                 | 0.0362                  | 0.0430                  |\n",
    "| 18     | 100    | 2154    | 0.6   | 0.75    | 0.9689    | 0.0276                    | 0.0017                     | -0.0275                     | 0.0011                       | 0.9540                 | 0.0872                  | 0.0472                  |\n",
    "| 19     | 100    | 2154    | 0.6   | 1.00    | 0.9900    | 0.0313                    | 0.0030                     | -0.0313                     | -0.0027                      | 1.0000                 | 0.0782                  | 0.0525                  |\n",
    "| 20     | 100    | 2154    | 0.6   | 1.25    | 0.9968    | 0.0309                    | 0.0022                     | -0.0309                     | -0.0019                      | 0.9975                 | 0.0165                  | 0.0738                  |\n",
    "| 21     | 100    | 316     | 0.8   | 0.75    | 0.9689    | 0.0277                    | 0.0036                     | -0.0276                     | 0.0011                       | 0.2525                 | 0.0798                  | 0.0450                  |\n",
    "| 22     | 100    | 316     | 0.8   | 1.00    | 0.9900    | 0.0315                    | 0.0042                     | -0.0314                     | -0.0027                      | 0.6040                 | 0.0693                  | 0.0488                  |\n",
    "| 23     | 100    | 316     | 0.8   | 1.25    | 0.9968    | 0.0310                    | 0.0036                     | -0.0309                     | -0.0019                      | 0.3733                 | 0.0140                  | 0.0528                  |\n",
    "| 24     | 100    | 100     | 1.0   | 0.75    | 0.9689    | 0.0282                    | 0.0062                     | -0.0279                     | 0.0009                       | 0.1003                 | 0.0853                  | 0.0485                  |\n",
    "| 25     | 100    | 100     | 1.0   | 1.00    | 0.9900    | 0.0319                    | 0.0064                     | -0.0317                     | -0.0029                      | 0.2130                 | 0.0650                  | 0.0465                  |\n",
    "| 26     | 100    | 100     | 1.0   | 1.25    | 0.9968    | 0.0314                    | 0.0058                     | -0.0312                     | -0.0021                      | 0.1220                 | 0.0240                  | 0.0472                  |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gonçalves, S., & Kaffo, M. (2015). Bootstrap inference for linear dynamic panel data models with individual fixed effects. Journal of Econometrics, 186(2), 407–426. https://doi.org/10.1016/j.jeconom.2015.02.017\n",
    "\n",
    "Hahn, J., & Kuersteiner, G. (2002). Asymptotically unbiased inference for a dynamic panel model with fixed effects when both n and T are large. Econometrica, 70(4), 1639–1657. https://doi.org/10.1111/1468-0262.00342\n",
    "\n",
    "Nickell, S. (1981). Biases in dynamic models with fixed effects. Econometrica, 49(6), 1417–1426. https://doi.org/10.2307/1911408"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
